@inproceedings{Weiser81,
author = {Weiser, Mark},
title = {Program slicing},
year = {1981},
isbn = {0897911466},
publisher = {IEEE Press},
booktitle = {Proceedings of the 5th International Conference on Software Engineering},
pages = {439–449},
numpages = {11},
keywords = {Software tools, Program metrics, Program maintenance, Human factors, Debugging, Data flow analysis},
location = {San Diego, California, USA},
series = {ICSE '81}
}


@inproceedings{peep84,
author = {Davidson, Jack W. and Fraser, Christopher W.},
title = {{Automatic Generation of Peephole Optimizations}},
year = {1984},
doi = {10.1145/502874.502885},
pages = {111--116},
location = {Montreal, Canada},
series = {SIGPLAN '84},
booktitle = {Proceedings of the 1984 SIGPLAN Symposium on Compiler Construction},
}

@inbook{alive2,
author = {Lopes, Nuno P. and Lee, Juneyoung and Hur, Chung-Kil and Liu, Zhengyang and Regehr, John},
title = {{Alive2: Bounded Translation Validation for LLVM}},
year = {2021},
isbn = {9781450383912},
url = {https://doi.org/10.1145/3453483.3454030},
abstract = {We designed, implemented, and deployed Alive2: a bounded translation validation tool for the LLVM compiler’s intermediate representation (IR). It limits resource consumption by, for example, unrolling loops up to some bound, which means there are circumstances in which it misses bugs. Alive2 is designed to avoid false alarms, is fully automatic through the use of an SMT solver, and requires no changes to LLVM. By running Alive2 over LLVM’s unit test suite, we discovered and reported 47 new bugs, 28 of which have been fixed already. Moreover, our work has led to eight patches to the LLVM Language Reference—the definitive description of the semantics of its IR—and we have participated in numerous discussions with the goal of clarifying ambiguities and fixing errors in these semantics. Alive2 is open source and we also made it available on the web, where it has active users from the LLVM community.},
booktitle = {Proceedings of the 42nd ACM SIGPLAN International Conference on Programming Language Design and Implementation},
pages = {65–79},
numpages = {15}
}

@inproceedings{taming,
author = {Lee, Juneyoung and Kim, Yoonseung and Song, Youngju and Hur, Chung-Kil and Das, Sanjoy and Majnemer, David and Regehr, John and Lopes, Nuno P.},
title = {{Taming Undefined Behavior in LLVM}},
year = {2017},
isbn = {9781450349888},
url = {https://doi.org/10.1145/3062341.3062343},
doi = {10.1145/3062341.3062343},
abstract = { A central concern for an optimizing compiler is the design of its intermediate representation (IR) for code. The IR should make it easy to perform transformations, and should also afford efficient and precise static analysis. In this paper we study an aspect of IR design that has received little attention: the role of undefined behavior. The IR for every optimizing compiler we have looked at, including GCC, LLVM, Intel's, and Microsoft's, supports one or more forms of undefined behavior (UB), not only to reflect the semantics of UB-heavy programming languages such as C and C++, but also to model inherently unsafe low-level operations such as memory stores and to avoid over-constraining IR semantics to the point that desirable transformations become illegal. The current semantics of LLVM's IR fails to justify some cases of loop unswitching, global value numbering, and other important "textbook" optimizations, causing long-standing bugs. We present solutions to the problems we have identified in LLVM's IR and show that most optimizations currently in LLVM remain sound, and that some desirable new transformations become permissible. Our solutions do not degrade compile time or performance of generated code. },
booktitle = {Proceedings of the 38th ACM SIGPLAN Conference on Programming Language Design and Implementation},
pages = {633–647},
numpages = {15},
keywords = {compilers, undefined behavior, intermediate representations},
location = {Barcelona, Spain},
series = {PLDI 2017}
}

@InProceedings{LLVM:CGO04,
  author    = {Chris Lattner and Vikram Adve},
  title     = "{{LLVM: A Compilation Framework for Lifelong Program Analysis \& Transformation}}",
  booktitle = "{Proceedings of the 2004 International Symposium on Code Generation and Optimization (CGO'04)}",
  address   = {Palo Alto, California},
  month     = {Mar},
  year      = {2004}
}

@article{souper,
  title={Souper: A synthesizing superoptimizer},
  author={Sasnauskas, Raimondas and Chen, Yang and Collingbourne, Peter and Ketema, Jeroen and Lup, Gratian and Taneja, Jubi and Regehr, John},
  journal={arXiv preprint arXiv:1711.04422},
  year={2017}
}

@inproceedings{rake,
author = {Ahmad, Maaz Bin Safeer and Root, Alexander J. and Adams, Andrew and Kamil, Shoaib and Cheung, Alvin},
title = {{Vector Instruction Selection for Digital Signal Processors Using Program Synthesis}},
year = {2022},
isbn = {9781450392051},
doi = {10.1145/3503222.3507714},
booktitle = {Proceedings of the 27th ACM International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {1004–1016},
numpages = {13},
location = {Lausanne, Switzerland},
series = {ASPLOS 2022}
}

@inbook{vegen,
author = {Chen, Yishen and Mendis, Charith and Carbin, Michael and Amarasinghe, Saman},
title = {{VeGen: A Vectorizer Generator for SIMD and Beyond}},
year = {2021},
isbn = {9781450383172},
url = {https://doi.org/10.1145/3445814.3446692},
abstract = {Vector instructions are ubiquitous in modern processors. Traditional compiler auto-vectorization techniques have focused on targeting single instruction multiple data (SIMD) instructions. However, these auto-vectorization techniques are not sufficiently powerful to model non-SIMD vector instructions, which can accelerate applications in domains such as image processing, digital signal processing, and machine learning. To target non-SIMD instruction, compiler developers have resorted to complicated, ad hoc peephole optimizations, expending significant development time while still coming up short. As vector instruction sets continue to rapidly evolve, compilers cannot keep up with these new hardware capabilities.  In this paper, we introduce Lane Level Parallelism (LLP), which captures the model of parallelism implemented by both SIMD and non-SIMD vector instructions. We present VeGen, a vectorizer generator that automatically generates a vectorization pass to uncover target-architecture-specific LLP in programs while using only instruction semantics as input. VeGen decouples, yet coordinates automatically generated target-specific vectorization utilities with its target-independent vectorization algorithm. This design enables us to systematically target non-SIMD vector instructions that until now require ad hoc coordination between different compiler stages. We show that VeGen can use non-SIMD vector instructions effectively, for example, getting speedup 3\texttimes{} (compared to LLVM’s vectorizer) on x265’s idct4 kernel.},
booktitle = {Proceedings of the 26th ACM International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {902–914},
numpages = {13}
}

@misc{llvmmca,
  author = {LLVM Developers},
  year = {2023},
  title = {{LLVM Machine Code Analyzer}},
  url = {https://llvm.org/docs/CommandGuide/llvm-mca.html},
}

@article{dfa_pruning,
author = {Mukherjee, Manasij and Kant, Pranav and Liu, Zhengyang and Regehr, John},
title = {{Dataflow-Based Pruning for Speeding up Superoptimization}},
year = {2020},
issue_date = {November 2020},
volume = {4},
number = {OOPSLA},
url = {https://doi.org/10.1145/3428245},
doi = {10.1145/3428245},
abstract = {Superoptimization is a compilation strategy that uses search to improve code quality, rather than relying on a canned sequence of transformations, as traditional optimizing compilers do. This search can be seen as a program synthesis problem: from unoptimized code serving as a specification, the synthesis procedure attempts to create a more efficient implementation. An important family of synthesis algorithms works by enumerating candidates and then successively checking if each refines the specification, using an SMT solver. The contribution of this paper is a pruning technique which reduces the enumerative search space using fast dataflow-based techniques to discard synthesis candidates that contain symbolic constants and uninstantiated instructions. We demonstrate the effectiveness of this technique by improving the runtime of an enumerative synthesis procedure in the Souper superoptimizer for the LLVM intermediate representation. The techniques presented in this paper eliminate 65% of the solver calls made by Souper, making it 2.32x faster (14.54 hours vs 33.76 hours baseline, on a large multicore) at solving all 269,113 synthesis problems that Souper encounters when optimizing the C and C++ programs from SPEC CPU 2017.},
journal = {Proc. ACM Program. Lang.},
month = {nov},
articleno = {177},
numpages = {24},
keywords = {abstract interpretation, program synthesis, superoptimization, pruning}
}

@inproceedings{ithemal,
  title={Ithemal: Accurate, portable and fast basic block throughput estimation using deep neural networks},
  author={Mendis, Charith and Renda, Alex and Amarasinghe, Saman and Carbin, Michael},
  booktitle={International Conference on Machine Learning},
  pages={4505--4515},
  year={2019},
  organization={PMLR}
}


@inproceedings{Bansal06,
  author = {Bansal, Sorav and Aiken, Alex},
  title = {{Automatic Generation of Peephole Superoptimizers}},
  year = {2006},
  isbn = {1595934510},
  url = {https://doi.org/10.1145/1168857.1168906},
  doi = {10.1145/1168857.1168906},
  abstract = {Peephole optimizers are typically constructed using human-written pattern matching rules, an approach that requires expertise and time, as well as being less than systematic at exploiting all opportunities for optimization. We explore fully automatic construction of peephole optimizers using brute force superoptimization. While the optimizations discovered by our automatic system may be less general than human-written counterparts, our approach has the potential to automatically learn a database of thousands to millions of optimizations, in contrast to the hundreds found in current peephole optimizers. We show experimentally that our optimizer is able to exploit performance opportunities not found by existing compilers; in particular, we show speedups from 1.7 to a factor of 10 on some compute intensive kernels over a conventional optimizing compiler.},
  booktitle = {Proceedings of the 12th International Conference on Architectural Support for Programming Languages and Operating Systems},
  pages = {394–403},
  numpages = {10},
  keywords = {code selection, peephole optimization, superoptimization},
  location = {San Jose, California, USA},
  series = {ASPLOS XII}
}

@inproceedings{stoke,
author = {Schkufza, Eric and Sharma, Rahul and Aiken, Alex},
title = {{Stochastic Superoptimization}},
year = {2013},
isbn = {9781450318709},
url = {https://doi.org/10.1145/2451116.2451150},
doi = {10.1145/2451116.2451150},
abstract = {We formulate the loop-free binary superoptimization task as a stochastic search problem. The competing constraints of transformation correctness and performance improvement are encoded as terms in a cost function, and a Markov Chain Monte Carlo sampler is used to rapidly explore the space of all possible programs to find one that is an optimization of a given target program. Although our method sacrifices completeness, the scope of programs we are able to consider, and the resulting quality of the programs that we produce, far exceed those of existing superoptimizers. Beginning from binaries compiled by llvm -O0 for 64-bit x86, our prototype implementation, STOKE, is able to produce programs which either match or outperform the code produced by gcc -O3, icc -O3, and in some cases, expert handwritten assembly.},
booktitle = {Proceedings of the Eighteenth International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {305–316},
numpages = {12},
keywords = {stochastic search, markov chain monte carlo, smt, superoptimization, x86, binary, x86-64, 64-bit, mcmc},
location = {Houston, Texas, USA},
series = {ASPLOS '13}
}



@inproceedings{ml_syn,
author = {Cowan, Meghan and Moreau, Thierry and Chen, Tianqi and Bornholt, James and Ceze, Luis},
title = {{Automatic Generation of High-Performance Quantized Machine Learning Kernels}},
year = {2020},
isbn = {9781450370479},
url = {https://doi.org/10.1145/3368826.3377912},
doi = {10.1145/3368826.3377912},
abstract = {Quantization optimizes machine learning inference for resource constrained environments by reducing the precision of its computation. In the extreme, even single-bit computations can produce acceptable results at dramatically lower cost. But this ultra-low-precision quantization is difficult to exploit because extracting optimal performance requires hand-tuning both high-level scheduling decisions and low-level implementations. As a result, practitioners settle for a few predefined quantized kernels, sacrificing optimality and restricting their ability to adapt to new hardware. This paper presents a new automated approach to implementing quantized inference for machine learning models. We integrate the choice of how to lay out quantized values into the scheduling phase of a machine learning compiler, allowing it to be optimized in concert with tiling and parallelization decisions. After scheduling, we use program synthesis to automatically generate efficient low-level operator implementations for the desired precision and data layout. We scale up synthesis using a novel reduction sketch that exploits the structure of matrix multiplication. On a ResNet18 model, our generated code outperforms an optimized floating-point baseline by up to 3.9\texttimes{}, and a state-of-the-art quantized implementation by up to 16.6\texttimes{}.},
booktitle = {Proceedings of the 18th ACM/IEEE International Symposium on Code Generation and Optimization},
pages = {305–316},
numpages = {12},
keywords = {quantization, machine learning, synthesis},
location = {San Diego, CA, USA},
series = {CGO 2020}
}

@inproceedings{rosette,
author = {Torlak, Emina and Bodik, Rastislav},
title = {{Growing Solver-Aided Languages with Rosette}},
year = {2013},
isbn = {9781450324724},
url = {https://doi.org/10.1145/2509578.2509586},
doi = {10.1145/2509578.2509586},
abstract = {SAT and SMT solvers have automated a spectrum of programming tasks, including program synthesis, code checking, bug localization, program repair, and programming with oracles. In principle, we obtain all these benefits by translating the program (once) to a constraint system understood by the solver. In practice, however, compiling a language to logical formulas is a tricky process, complicated by having to map the solution back to the program level and extend the language with new solver-aided constructs, such as symbolic holes used in synthesis.This paper introduces ROSETTE, a framework for designing solver-aided languages. ROSETTE is realized as a solver-aided language embedded in Racket, from which it inherits extensive support for meta-programming. Our framework frees designers from having to compile their languages to constraints: new languages, and their solver-aided constructs, are defined by shallow (library-based) or deep (interpreter-based) embedding in ROSETTE itself.We describe three case studies, by ourselves and others, of using ROSETTE to implement languages and synthesizers for web scraping, spatial programming, and superoptimization of bitvector programs.},
booktitle = {Proceedings of the 2013 ACM International Symposium on New Ideas, New Paradigms, and Reflections on Programming \& Software},
pages = {135–152},
numpages = {18},
keywords = {solver-aided languages},
location = {Indianapolis, Indiana, USA},
series = {Onward! 2013}
}

@inproceedings{sparse,
author = {Horro, Marcos and Pouchet, Louis-Noël and Rodríguez, Gabriel and Tourino, Juan},
title = {{Custom High-Performance Vector Code Generation for Data-Specific Sparse Computations}},
year = {2022},
abstract = {Sparse computations, such as sparse matrix-dense vector multiplication, are notoriously hard to optimize due to their irregularity and memory-boundedness. Solutions to improve the performance of sparse computations have been proposed, ranging from hardwarebased such as gather-scatter instructions, to software ones such as generalized and dedicated sparse formats, used together with specialized executor programs for different hardware targets. These sparse computations are often performed on read-only sparse structures: while the data themselves are variable, the sparsity structure itself does not change. Indeed, sparse formats such as CSR have a typically high cost to insert/remove nonzero elements in the representation. The typical use case is to not modify the sparsity during possibly repeated computations on the same sparse structure. In this work, we exploit the possibility to generate a specialized executor program dedicated to the particular sparsity structure of an input matrix. It creates opportunities to remove indirection arrays and synthesize regular, vectorizable code for such computations. But, at the same time, it introduces challenges in code size and instruction generation, as well as effcient SIMD vectorization. We present novel techniques and extensive experimental results to effciently generate SIMD vector code for data-specific sparse computations, and study the limits in terms of applicability and performance of our techniques compared to state-of-practice highperformance libraries like Intel MKL.},
booktitle = {Proceedings of the 31st International Conference on Parallel Architectures and Compilation Techniques},
}

@misc{MemorySSA,
author = "{LLVM Developers}",
title = {{MemorySSA}},
url = {https://llvm.org/docs/MemorySSA.html},
year = 2023,
}


@misc{loopinfo,
author = "{LLVM Developers}",
title = {{LoopInfo}},
url = {https://llvm.org/doxygen/classllvm_1_1LoopInfo.html},
year = 2023,
}

@inproceedings{slp,
author = {Larsen, Samuel and Amarasinghe, Saman},
title = {{Exploiting Superword Level Parallelism with Multimedia Instruction Sets}},
year = {2000},
isbn = {1581131992},
url = {https://doi.org/10.1145/349299.349320},
doi = {10.1145/349299.349320},
abstract = {Increasing focus on multimedia applications has prompted the addition of multimedia extensions to most existing general purpose microprocessors. This added functionality comes primarily with the addition of short SIMD instructions. Unfortunately, access to these instructions is limited to in-line assembly and library calls. Generally, it has been assumed that vector compilers provide the most promising means of exploiting multimedia instructions. Although vectorization technology is well understood, it is inherently complex and fragile. In addition, it is incapable of locating SIMD-style parallelism within a basic block.In this paper we introduce the concept of Superword Level Parallelism (SLP) ,a novel way of viewing parallelism in multimedia and scientific applications. We believe SLPP is fundamentally different from the loop level parallelism exploited by traditional vector processing, and therefore demands a new method of extracting it. We have developed a simple and robust compiler for detecting SLPP that targets basic blocks rather than loop nests. As with techniques designed to extract ILP, ours is able to exploit parallelism both across loop iterations and within basic blocks. The result is an algorithm that provides excellent performance in several application domains. In our experiments, dynamic instruction counts were reduced by 46%. Speedups ranged from 1.24 to 6.70.},
booktitle = {Proceedings of the ACM SIGPLAN 2000 Conference on Programming Language Design and Implementation},
pages = {145–156},
numpages = {12},
location = {Vancouver, British Columbia, Canada},
series = {PLDI '00}
}



@inproceedings{diospyros,
author = {VanHattum, Alexa and Nigam, Rachit and Lee, Vincent T. and Bornholt, James and Sampson, Adrian},
title = {{Vectorization for Digital Signal Processors via Equality Saturation}},
year = {2021},
isbn = {9781450383172},
url = {https://doi.org/10.1145/3445814.3446707},
doi = {10.1145/3445814.3446707},
abstract = {Applications targeting digital signal processors (DSPs) benefit from fast implementations of small linear algebra kernels. While existing auto-vectorizing compilers are effective at extracting performance from large kernels, they struggle to invent the complex data movements necessary to optimize small kernels. To get the best performance, DSP engineers must hand-write and tune specialized small kernels for a wide spectrum of applications and architectures. We present Diospyros, a search-based compiler that automatically finds efficient vectorizations and data layouts for small linear algebra kernels. Diospyros combines symbolic evaluation and equality saturation to vectorize computations with irregular structure. We show that a collection of Diospyros-compiled kernels outperform implementations from existing DSP libraries by 3.1\texttimes{} on average, that Diospyros can generate kernels that are competitive with expert-tuned code, and that optimizing these small kernels offers end-to-end speedup for a DSP application.},
booktitle = {Proceedings of the 26th ACM International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {874–886},
numpages = {13},
keywords = {Equality Saturation, DSPs, Program Synthesis, Vectorization},
location = {Virtual, USA},
series = {ASPLOS '21}
}

@inproceedings{swizzleinventor,
author = {Phothilimthana, Phitchaya Mangpo and Elliott, Archibald Samuel and Wang, An and Jangda, Abhinav and Hagedorn, Bastian and Barthels, Henrik and Kaufman, Samuel J. and Grover, Vinod and Torlak, Emina and Bodik, Rastislav},
title = {{Swizzle Inventor: Data Movement Synthesis for GPU Kernels}},
year = {2019},
isbn = {9781450362405},
url = {https://doi.org/10.1145/3297858.3304059},
doi = {10.1145/3297858.3304059},
abstract = {Utilizing memory and register bandwidth in modern architectures may require swizzles --- non-trivial mappings of data and computations onto hardware resources --- such as shuffles. We develop Swizzle Inventor to help programmers implement swizzle programs, by writing program sketches that omit swizzles and delegating their creation to an automatic synthesizer. Our synthesis algorithm scales to real-world programs, allowing us to invent new GPU kernels for stencil computations, matrix transposition, and a finite field multiplication algorithm (used in cryptographic applications). The synthesized 2D convolution and finite field multiplication kernels are on average 1.5--3.2x and 1.1--1.7x faster, respectively, than expert-optimized CUDA kernels.},
booktitle = {Proceedings of the Twenty-Fourth International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {65–78},
numpages = {14},
keywords = {GPGPU, program synthesis, swizzling},
location = {Providence, RI, USA},
series = {ASPLOS '19}
}

@article{halide,
author = {Ragan-Kelley, Jonathan and Adams, Andrew and Sharlet, Dillon and Barnes, Connelly and Paris, Sylvain and Levoy, Marc and Amarasinghe, Saman and Durand, Fr\'{e}do},
title = {{Halide: Decoupling Algorithms from Schedules for High-Performance Image Processing}},
year = {2017},
issue_date = {January 2018},
volume = {61},
number = {1},
issn = {0001-0782},
url = {https://doi.org/10.1145/3150211},
doi = {10.1145/3150211},
abstract = {Writing high-performance code on modern machines requires not just locally optimizing inner loops, but globally reorganizing computations to exploit parallelism and locality---doing things such as tiling and blocking whole pipelines to fit in cache. This is especially true for image processing pipelines, where individual stages do much too little work to amortize the cost of loading and storing results to and from off-chip memory. As a result, the performance difference between a naive implementation of a pipeline and one globally optimized for parallelism and locality is often an order of magnitude. However, using existing programming tools, writing high-performance image processing code requires sacrificing simplicity, portability, and modularity. We argue that this is because traditional programming models conflate the computations defining the algorithm with decisions about intermediate storage and the order of computation, which we call the schedule.We propose a new programming language for image processing pipelines, called Halide, that separates the algorithm from its schedule. Programmers can change the schedule to express many possible organizations of a single algorithm. The Halide compiler then synthesizes a globally combined loop nest for an entire algorithm, given a schedule. Halide models a space of schedules which is expressive enough to describe organizations that match or outperform state-of-the-art hand-written implementations of many computational photography and computer vision algorithms. Its model is simple enough to do so often in only a few lines of code, and small changes generate efficient implementations for x86, ARM, Graphics Processors (GPUs), and specialized image processors, all from a single algorithm.Halide has been public and open source for over four years, during which it has been used by hundreds of programmers to deploy code to tens of thousands of servers and hundreds of millions of phones, processing billions of images every day.},
journal = {Commun. ACM},
month = {dec},
pages = {106–115},
numpages = {10}
}


@article{peepholegeneration,
author = {Davidson, Jack W. and Fraser, Christopher W.},
title = {{Automatic Generation of Peephole Optimizations}},
year = {2004},
issue_date = {April 2004},
volume = {39},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/989393.989407},
doi = {10.1145/989393.989407},
abstract = {This paper describes a system that automatically generates peephole optimizations. A general peephole optimizer driven by a machine description produces optimizations at compile-compile time for a fast, pattern-directed, compile-time optimizer. They form part of a compiler that simplifies retargeting by substituting peephole optimization for case analysis.},
journal = {SIGPLAN Not.},
month = {apr},
pages = {104–111},
numpages = {8}
}

@inproceedings{massalin,
author = {Massalin, Henry},
title = {Superoptimizer: A Look at the Smallest Program},
year = {1987},
isbn = {0818608056},
url = {https://doi.org/10.1145/36206.36194},
doi = {10.1145/36206.36194},
abstract = {Given an instruction set, the superoptimizer finds the shortest program to compute a function. Startling programs have been generated, many of them engaging in convoluted bit-fiddling bearing little resemblance to the source programs which defined the functions. The key idea in the superoptimizer is a probabilistic test that makes exhaustive searches practical for programs of useful size. The search space is defined by the processor's instruction set, which may include the whole set, but it is typically restricted to a subset. By constraining the instructions and observing the effect on the output program, one can gain insight into the design of instruction sets. In addition, superoptimized programs may be used by peephole optimizers to improve the quality of generated code, or by assembly language programmers to improve manually written code.},
booktitle = {Proceedings of the Second International Conference on Architectual Support for Programming Languages and Operating Systems},
pages = {122–126},
numpages = {5},
location = {Palo Alto, California, USA},
series = {ASPLOS II}
}

@article{peephole-gen,
author = {Davidson, Jack W. and Fraser, Christopher W.},
title = {{Automatic Generation of Peephole Optimizations}},
year = {2004},
issue_date = {April 2004},
volume = {39},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/989393.989407},
doi = {10.1145/989393.989407},
abstract = {This paper describes a system that automatically generates peephole optimizations. A general peephole optimizer driven by a machine description produces optimizations at compile-compile time for a fast, pattern-directed, compile-time optimizer. They form part of a compiler that simplifies retargeting by substituting peephole optimization for case analysis.},
journal = {SIGPLAN Not.},
month = {apr},
pages = {104–111},
numpages = {8}
}

@inproceedings{optgen,
  title={Optgen: A generator for local optimizations},
  author={Buchwald, Sebastian},
  booktitle={International Conference on Compiler Construction},
  pages={171--189},
  year={2015},
  organization={Springer}
}

@inproceedings{sccl,
author = {Cai, Zixian and Liu, Zhengyang and Maleki, Saeed and Musuvathi, Madanlal and Mytkowicz, Todd and Nelson, Jacob and Saarikivi, Olli},
title = {{Synthesizing Optimal Collective Algorithms}},
year = {2021},
isbn = {9781450382946},
url = {https://doi.org/10.1145/3437801.3441620},
doi = {10.1145/3437801.3441620},
abstract = {Collective communication algorithms are an important component of distributed computation. Indeed, in the case of deep-learning, collective communication is the Amdahl's bottleneck of data-parallel training.This paper introduces SCCL (for Synthesized Collective Communication Library), a systematic approach to synthesizing collective communication algorithms that are explicitly tailored to a particular hardware topology. SCCL synthesizes algorithms along the Pareto-frontier spanning from latency-optimal to bandwidth-optimal implementations of a collective. The paper demonstrates how to encode the synthesis problem as a quantifier-free SMT formula which can be discharged to a theorem prover. We show how our carefully built encoding enables SCCL to scale.We synthesize novel latency and bandwidth optimal algorithms not seen in the literature on two popular hardware topologies. We also show how SCCL efficiently lowers algorithms to implementations on two hardware architectures (NVIDIA and AMD) and demonstrate competitive performance with hand optimized collective communication libraries.},
booktitle = {Proceedings of the 26th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming},
pages = {62–75},
numpages = {14},
keywords = {synthesis, interconnection, GPU, network, collective communication},
location = {Virtual Event, Republic of Korea},
series = {PPoPP '21}
}

@inproceedings{sketch,
author = {Solar-Lezama, Armando},
title = {{The Sketching Approach to Program Synthesis}},
year = {2009},
isbn = {9783642106712},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-10672-9_3},
doi = {10.1007/978-3-642-10672-9_3},
abstract = {Sketching is a new form of localized software synthesis that aims to bridge the gap between a programmer's high-level insights about a problem and the computer's ability to manage low-level details. In sketching, the programmer uses partial programs to describe the desired implementation <em>strategy</em> , and leaves the low-level details of the implementation to an automated synthesis procedure. This paper describes the sketching approach to program synthesis, including the details of the <emphasis type="SmallCaps">Sketch</emphasis> language and synthesizer. The paper will then describe some of the techniques that make synthesis from sketches possible, and will close with a brief discussion of open problems in programmer guided synthesis.},
booktitle = {Proceedings of the 7th Asian Symposium on Programming Languages and Systems},
pages = {4–13},
numpages = {10},
location = {Seoul, Korea},
series = {APLAS '09}
}

@misc{spec17,
    author = {Standard Performance Evaluation Corporation},
    title = {{SPEC CPU{\textsuperscript{\textregistered}} 2017}},
    note = {https://www.spec.org/cpu2017/Docs/overview.html#benchmarks}
}

@inproceedings{equalitysat,
author = {Tate, Ross and Stepp, Michael and Tatlock, Zachary and Lerner, Sorin},
title = {{Equality Saturation: A New Approach to Optimization}},
year = {2009},
isbn = {9781605583792},
url = {https://doi.org/10.1145/1480881.1480915},
doi = {10.1145/1480881.1480915},
abstract = {Optimizations in a traditional compiler are applied sequentially, with each optimization destructively modifying the program to produce a transformed program that is then passed to the next optimization. We present a new approach for structuring the optimization phase of a compiler. In our approach, optimizations take the form of equality analyses that add equality information to a common intermediate representation. The optimizer works by repeatedly applying these analyses to infer equivalences between program fragments, thus saturating the intermediate representation with equalities. Once saturated, the intermediate representation encodes multiple optimized versions of the input program. At this point, a profitability heuristic picks the final optimized program from the various programs represented in the saturated representation. Our proposed way of structuring optimizers has a variety of benefits over previous approaches: our approach obviates the need to worry about optimization ordering, enables the use of a global optimization heuristic that selects among fully optimized programs, and can be used to perform translation validation, even on compilers other than our own. We present our approach, formalize it, and describe our choice of intermediate representation. We also present experimental results showing that our approach is practical in terms of time and space overhead, is effective at discovering intricate optimization opportunities, and is effective at performing translation validation for a realistic optimizer.},
booktitle = {Proceedings of the 36th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
pages = {264–276},
numpages = {13},
keywords = {equality reasoning, compiler optimization, intermediate representation},
location = {Savannah, GA, USA},
series = {POPL '09}
}

@misc{hexagon,
  author = {Qualcomm Technologies},
  title = {Hexagon DSP SDK},
  url = {https://developer.qualcomm.com/software/hexagon-dsp-sdk}
}

@misc{orc,
  author = "{LLVM Developers}",
  title = {{ORC Design and Implementation}},
  url = {https://llvm.org/docs/ORCv2.html},
  year = 2023,
}

@misc{tti,
  author = "{LLVM Developers}",
  title = {{TargetTransformInfo Class Reference}},
  url = {https://llvm.org/doxygen/classllvm_1_1TargetTransformInfo.html},
  year = 2023,
}

@inproceedings{z3,
  title={Z3: An efficient SMT solver},
  author={De Moura, Leonardo and Bj{\o}rner, Nikolaj},
  booktitle={Tools and Algorithms for the Construction and Analysis of Systems: 14th International Conference, TACAS 2008, Held as Part of the Joint European Conferences on Theory and Practice of Software, ETAPS 2008, Budapest, Hungary, March 29-April 6, 2008. Proceedings 14},
  pages={337--340},
  year={2008},
  organization={Springer}
}


@misc{neon,
  author = "{ARM}",
  title = {{ARM NEON Architecture}},
  url = {https://developer.arm.com/Architectures/Neon},
  year = 2023,
}


@misc{intelguide,
  author = "{Intel}",
  title = {{Intel Intrinsics Guide}},
  url = {https://www.intel.com/content/www/us/en/docs/intrinsics-guide/index.html},
  year = 2023,
}

@inproceedings{difftune,
  title={Difftune: Optimizing cpu simulator parameters with learned differentiable surrogates},
  author={Renda, Alex and Chen, Yishen and Mendis, Charith and Carbin, Michael},
  booktitle={2020 53rd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)},
  pages={442--455},
  year={2020},
  organization={IEEE}
}

@inproceedings{laukemann,
  title={Automatic throughput and critical path analysis of x86 and ARM assembly kernels},
  author={Laukemann, Jan and Hammer, Julian and Hager, Georg and Wellein, Gerhard},
  booktitle={2019 IEEE/ACM Performance Modeling, Benchmarking and Simulation of High Performance Computer Systems (PMBS)},
  pages={1--6},
  year={2019},
  organization={IEEE}
}


@misc{cascadelake,
  author = "{Intel}",
  title = {{Cascade Lake: Overview}},
  url = {https://www.intel.com/content/www/us/en/products/platforms/details/cascade-lake.html},
  year = 2023,
}

@misc{zen3,
  author = "{AMD}",
  title = {{AMD Zen 3}},
  url = {https://www.amd.com/en/technologies/zen-core},
  year = 2023,
}

@article{stoke-fp,
  title={Stochastic optimization of floating-point programs with tunable precision},
  author={Schkufza, Eric and Sharma, Rahul and Aiken, Alex},
  journal={ACM SIGPLAN Notices},
  volume={49},
  number={6},
  pages={53--64},
  year={2014},
  publisher={ACM New York, NY, USA}
}

@article{conditionally,
  title={Conditionally correct superoptimization},
  author={Sharma, Rahul and Schkufza, Eric and Churchill, Berkeley and Aiken, Alex},
  journal={ACM SIGPLAN Notices},
  volume={50},
  number={10},
  pages={147--162},
  year={2015},
  publisher={ACM New York, NY, USA}
}

 @article{woodruff2023rewriting,
  title={Rewriting History: Repurposing Domain-Specific CGRAs},
  author={Woodruff, Jackson and Koehler, Thomas and Brauckmann, Alexander and Cummins, Chris and Ainsworth, Sam and O'Boyle, Michael FP},
  journal={arXiv preprint arXiv:2309.09112},
  year={2023}
}


@article{hockney1994communication,
  title={The communication challenge for MPP: Intel Paragon and Meiko CS-2},
  author={Hockney, Roger W},
  journal={Parallel computing},
  volume={20},
  number={3},
  pages={389--398},
  year={1994},
  publisher={Elsevier}
}

@article{chan2007collective,
  title={Collective communication: theory, practice, and experience},
  author={Chan, Ernie and Heimlich, Marcel and Purkayastha, Avi and Van De Geijn, Robert},
  journal={Concurrency and Computation: Practice and Experience},
  volume={19},
  number={13},
  pages={1749--1783},
  year={2007},
  publisher={Wiley Online Library}
}

@article{pjevsivac2007performance,
  title={Performance analysis of MPI collective operations},
  author={Pje{\v{s}}ivac-Grbovi{\'c}, Jelena and Angskun, Thara and Bosilca, George and Fagg, Graham E and Gabriel, Edgar and Dongarra, Jack J},
  journal={Cluster Computing},
  volume={10},
  number={2},
  pages={127--143},
  year={2007},
  publisher={Springer}
}

@article{mpich,
title = "A high-performance, portable implementation of the MPI message passing interface standard",
journal = "Parallel Computing",
volume = "22",
number = "6",
pages = "789 - 828",
year = "1996",
issn = "0167-8191",
doi = "https://doi.org/10.1016/0167-8191(96)00024-5",
url = "http://www.sciencedirect.com/science/article/pii/0167819196000245",
author = "William Gropp and Ewing Lusk and Nathan Doss and Anthony Skjellum",
keywords = "Message passing interface, Parallel programming environment, Benchmark, Performance, Portability, MPI-2"
}

@article{thakur2005optimization,
  title={Optimization of collective communication operations in MPICH},
  author={Thakur, Rajeev and Rabenseifner, Rolf and Gropp, William},
  journal={The International Journal of High Performance Computing Applications},
  volume={19},
  number={1},
  pages={49--66},
  year={2005},
  publisher={Sage Publications Sage CA: Thousand Oaks, CA}
}

@inproceedings{barnett1993global,
  title={Global combine on mesh architectures with wormhole routing},
  author={Barnett, Michael and Littlefield, Rick and Payne, David G and van de Geijn, Robert},
  booktitle={[1993] Proceedings Seventh International Parallel Processing Symposium},
  pages={156--162},
  year={1993},
  organization={IEEE}
}

@inproceedings{scott1991efficient,
  title={Efficient all-to-all communication patterns in hypercube and mesh topologies},
  author={Scott, David S},
  booktitle={The Sixth Distributed Memory Computing Conference, 1991. Proceedings},
  pages={398--399},
  year={1991},
  organization={IEEE Computer Society}
}

@inproceedings{bokhari1992complete,
  title={Complete exchange on a circuit switched mesh},
  author={Bokhari, Shahid H and Berryman, Harry},
  booktitle={1992 Proceedings Scalable High Performance Computing Conference},
  pages={300--301},
  year={1992},
  organization={IEEE Computer Society}
}

@inproceedings{sanders2002hierarchical,
  title={The hierarchical factor algorithm for all-to-all communication},
  author={Sanders, Peter and Tr{\"a}ff, Jesper Larsson},
  booktitle={European Conference on Parallel Processing},
  pages={799--803},
  year={2002},
  organization={Springer}
}

@inproceedings{sistare1999optimization,
  title={Optimization of MPI collectives on clusters of large-scale SMP's},
  author={Sistare, Steve and Vandevaart, Rolf and Loh, Eugene},
  booktitle={Proceedings of the 1999 ACM/IEEE conference on Supercomputing},
  pages={23--es},
  year={1999}
}

@inproceedings{tipparaju2003fast,
  title={Fast collective operations using shared and remote memory access protocols on clusters},
  author={Tipparaju, Vinod and Nieplocha, Jarek and Panda, Dhabaleswar},
  booktitle={Proceedings International Parallel and Distributed Processing Symposium},
  pages={10--pp},
  year={2003},
  organization={IEEE}
}

@inproceedings{traff2002improved,
  title={Improved MPI all-to-all communication on a Giganet SMP cluster},
  author={Tr{\"a}ff, Jesper Larsson},
  booktitle={European Parallel Virtual Machine/Message Passing Interface Users’ Group Meeting},
  pages={392--400},
  year={2002},
  organization={Springer}
}

@article{bruck1997efficient,
  title={Efficient algorithms for all-to-all communications in multiport message-passing systems},
  author={Bruck, Jehoshua and Ho, Ching-Tien and Kipnis, Shlomo and Upfal, Eli and Weathersby, Derrick},
  journal={IEEE Transactions on parallel and distributed systems},
  volume={8},
  number={11},
  pages={1143--1156},
  year={1997},
  publisher={IEEE}
}

@article{dongarra2013mpi,
  title={{MPI}: A message-passing interface standard version 3.0},
  author={Dongarra, Jack and others},
  journal={High Performance Computing Center Stuttgart (HLRS)},
  volume={2},
  number={5},
  pages={32},
  year={2013}
}

@inproceedings{gabriel2004open,
  title={{Open MPI: Goals, concept, and design of a next generation MPI implementation}},
  author={Gabriel, Edgar and Fagg, Graham E and Bosilca, George and Angskun, Thara and Dongarra, Jack J and Squyres, Jeffrey M and Sahay, Vishal and Kambadur, Prabhanjan and Barrett, Brian and Lumsdaine, Andrew and others},
  booktitle={European Parallel Virtual Machine/Message Passing Interface Users’ Group Meeting},
  pages={97--104},
  year={2004},
  organization={Springer}
}

@inproceedings{barnett1994building,
  title={Building a high-performance collective communication library},
  author={Barnett, Mike and Gupta, Satya and Payne, David G and Shuler, Lance and van de Geijn, Robert and Watts, Jerrell},
  booktitle={Supercomputing'94: Proceedings of the 1994 ACM/IEEE Conference on Supercomputing},
  pages={107--116},
  year={1994},
  organization={IEEE}
}

@inproceedings{wangt2018blink,
  title={Blink: A fast NVLink-based collective communication library},
  author={Wangt, Guanhua and Phanishayee, Amar and Venkataraman, Shivaram and Stoicat, Ion},
  booktitle={Proc. Conf. Syst. Mach. Learn.},
  year={2018}
}

@InProceedings{wang2020blink,
author = {Wang, Guanhua and Venkataraman, Shivaram and Phanishayee, Amar and Thelin, Jorgen and Devanur, Nikhil and Stoica, Ion},
title = {Blink: Fast and Generic Collectives for Distributed ML},
booktitle = {Conference on Machine Learning and Systems (MLSys 2020)},
year = {2020},
month = {March}
}

@inproceedings{zhang2017poseidon,
  title={Poseidon: An efficient communication architecture for distributed deep learning on {GPU} clusters},
  author={Zhang, Hao and Zheng, Zeyu and Xu, Shizhen and Dai, Wei and Ho, Qirong and Liang, Xiaodan and Hu, Zhiting and Wei, Jinliang and Xie, Pengtao and Xing, Eric P},
  booktitle={2017 {USENIX} Annual Technical Conference ({USENIX} {ATC} 17)},
  pages={181--193},
  year={2017}
}

@article{jayarajan2019priority,
  title={Priority-based parameter propagation for distributed DNN training},
  author={Jayarajan, Anand and Wei, Jinliang and Gibson, Garth and Fedorova, Alexandra and Pekhimenko, Gennady},
  booktitle = {Conference on Machine Learning and Systems (MLSys 2019)},
  year = {2019},
  month = {March}
}

@article{hashemi2019tictac,
  title={TicTac: Accelerating distributed deep learning with communication scheduling},
  author={Hashemi, Sayed Hadi and Jyothi, Sangeetha Abdu and Campbell, Roy H},
  booktitle = {Conference on Machine Learning and Systems (MLSys 2019)},
  year = {2019},
  month = {March}
}

@inproceedings{peng2019generic,
  title={A generic communication scheduler for distributed dnn training acceleration},
  author={Peng, Yanghua and Zhu, Yibo and Chen, Yangrui and Bao, Yixin and Yi, Bairen and Lan, Chang and Wu, Chuan and Guo, Chuanxiong},
  booktitle={Proceedings of the 27th ACM Symposium on Operating Systems Principles},
  pages={16--29},
  year={2019}
}

@INPROCEEDINGS{gdrcopy,
  author={R. {Shi} and S. {Potluri} and K. {Hamidouche} and J. {Perkins} and M. {Li} and D. {Rossetti} and D. K. D. K. {Panda}},
  booktitle={2014 21st International Conference on High Performance Computing (HiPC)},
  title={Designing efficient small message transfer mechanism for inter-node {MPI} communication on {InfiniBand} {GPU} clusters},
  year={2014},
  volume={},
  number={},
  pages={1-10},
}


@misc{graphcore,
key = {Graphcore IPU},
title = {Graphcore Intelligence Processing Unit},
note = {https://www.graphcore.ai/products/ipu},
year={2020},
}

@misc{gloo,
key = {Gloo Library},
title = {Gloo Collective Communications Library},
note = {https://github.com/facebookincubator/gloo},
year={2020},
}

@misc{ucx,
key = {UCX},
title = {Unified Communication X},
note = {https://www.openucx.org/},
year={2020},
}

@misc{nccl,
key = {NVIDIA NCCL Library},
title = {NVIDIA Collective Communications Library},
note = {https://github.com/NVIDIA/nccl},
year={2020},
}

@misc{rccl,
key = {AMD RCCL Library},
title = {ROCm Communication Collectives Library},
note = {https://github.com/ROCmSoftwarePlatform/rccl},
year={2020},
}

@misc{alex2018horovod,
    title={Horovod: fast and easy distributed deep learning in TensorFlow},
    author={Alexander Sergeev and Mike Del Balso},
    year={2018},
    eprint={1802.05799},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@ARTICLE{blueconnect,
  author={Cho, Minsik and Finkler, Ulrich and Serrano, Mauricio and Kung, David and Hunter, Hillery},
  journal={IBM Journal of Research and Development},
  title={BlueConnect: Decomposing all-reduce for deep learning on heterogeneous network hierarchy},
  year={2019},
  volume={63},
  number={6},
  pages={1:1-1:11},}

@incollection{plink,
 author = {Luo, Liang and West, Peter and Nelson, Jacob and Krishnamurthy, Arvind and Ceze, Luis},
 booktitle = {Proceedings of Machine Learning and Systems 2020},
 pages = {82--97},
 title = {PLink: Discovering and Exploiting Locality for Accelerated Distributed Training on the public Cloud},
 year = {2020}
}



@misc{mi50,
key = {AMD Radeon Instinct MI50},
title = {AMD Radeon Instinct MI50 Accelerator},
note = {https://www.amd.com/system/files/documents/radeon-instinct-mi50-datasheet.pdf},
year = {2020},
}

@misc{tpu,
key = {Google TPU},
title = {Google Cloud TPU},
note = {https://cloud.google.com/tpu},
year = {2020},
}

@article{nvlink1,
  author={D. {Foley} and J. {Danskin}},
  journal={IEEE Micro},
  title={Ultra-Performance Pascal GPU and NVLink Interconnect},
  year={2017},
  volume={37},
  number={2},
  pages={7-17},
  }

@article{nvlink2,
  author={J. {Choquette} and O. {Giroux} and D. {Foley}},
  journal={IEEE Micro},
  title={Volta: Performance and Programmability},
  year={2018},
  volume={38},
  number={2},
  pages={42-52},}

@ARTICLE{alphabeta,
	author={A. {Li} and S. L. {Song} and J. {Chen} and J. {Li} and X. {Liu} and N. R. {Tallent} and K. J. {Barker}},
	journal={IEEE Transactions on Parallel and Distributed Systems},
	title={Evaluating Modern GPU Interconnect: PCIe, NVLink, NV-SLI, NVSwitch and GPUDirect},
	year={2020},
	volume={31},
	number={1},
	pages={94-110},
	doi={10.1109/TPDS.2019.2928289}
}

@article{barrett2018satisfiability,
  title={Satisfiability modulo theories},
  author={Barrett, Clark and Tinelli, Cesare},
  journal={Handbook of model checking},
  pages={305--343},
  year={2018},
  publisher={Springer}
}
@misc{intelmanual,
key = {Intel 64 and IA-32 Architectures Software Developer Manuals},
title = {Intel 64 and IA-32 Architectures Software Developer Manuals},
note = {https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html},
year={2024},
}

@misc{killundef,
author = "{LLVM Developers}",
title = {RFC: Killing undef and spreading poison},
url = {https://lists.llvm.org/pipermail/llvm-dev/2016-December/107840.html},
year = 2016,
}

 @InProceedings{OpenMPI,
  author =	 {Joshua Hursey and Ethan Mallove and Jeffrey M. Squyres and Andrew Lumsdaine},
  title =	 {An Extensible Framework for Distributed Testing of MPI Implementations},
  booktitle =    {Proceedings, Euro PVM/MPI},
  year =         2007,
  address =      {Paris, France},
  month =        {October}
}

@inproceedings{spec2017,
author = {Bucek, James and Lange, Klaus-Dieter and v. Kistowski, J\'{o}akim},
title = {SPEC CPU2017: Next-Generation Compute Benchmark},
year = {2018},
isbn = {9781450356299},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3185768.3185771},
doi = {10.1145/3185768.3185771},
abstract = {Description of the new features of the SPEC CPU2017 industry standard benchmark and its metric calculations.},
booktitle = {Companion of the 2018 ACM/SPEC International Conference on Performance Engineering},
pages = {41–42},
numpages = {2},
keywords = {CPU, SPEC, compiler, performance},
location = {Berlin, Germany},
series = {ICPE '18}
}