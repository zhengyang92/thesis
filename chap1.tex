\chapter{Introduction}
\label{chap:intro}

My thesis is as follows:
%
Program synthesis can be used in performance optimization for novel
hardware platforms by generating optimized and verifiable code that
are tailored to the specific features and configurations of the target
architecture.
%
Specifically, this dissertation proposes a systematic approach to
synthesizing high-performance collective communication algorithms that
are proven to be correct and optimal for a given network topology, and
a synthesizing superoptimizer that can automatically generate peephole
optimizations for floating point and vector instructions that are
missing from a commodity compiler.

\section{Motivation}

Optimizing software for performance is a critical task in software
development.
%
Better software performance can lead to better user experiences, more
efficient resource utilization, and lower costs.
%
Performance optimization is becoming more important as the
scale of data and the complexity of applications continue to grow.


However, performance optimization is challenging, especially in the
post-Moore's Law era, the performance gains from improvements in
single core performance is diminishing, and the complexity of
software is increasing.
%
The emergence of novel architectures, such as novel vector processors
and specialized accelerators has further complicated the task.
%
These architectures offer unique features and capabilities that can
significantly improve the runtime performance, but leveraging these
features effectively requires more sophisticated optimization
techniques.

One approach to addressing these challenges is that human experts
rewrite the code from scratch in low-level languages or APIs, such as assembly
and C with intrinsics, to take advantage of the unique features of the
architecture. However, this has several drawbacks:

\begin{itemize}
%
\item Because of the increasing complexity of modern hardware,
implementing with low-level languages or APIs is error-prone and
time-consuming. Humans may need to spend a significant amount of time
to understand the architecture, for example, the Intel x86 programming
manual is over 4000 pages long. TODO citation. Code implemented in low
level languages or APIs are also difficult to understand, increasing
the likelihood of bugs and requiring more time for testing and
debugging.

\item On the other hand, the complexity of modern software makes it even
more difficult for human experts to make the right decisions about
instruction selection and scheduling, as a result, experts are likely
to focus on only a small subset of the code, such as inner loops,
rather than the entire application, which may lead to suboptimal
performance.

\item Programs optimized in this way are likely not portable and
may not be optimal if switching to different hardware platforms.
%
Either the code needs to be rewritten for each new platform, or the
code needs to be maintained and updated as the architecture evolves.

\end{itemize}


Another approach is to use an optimizing compiler.
%
Software developers have been using optimizing compilers to generate
efficient code for decades, and optimizing compilers have been proven
successful in generating efficient code for a wide range of
architectures.
%
Advanced optimization techniques, such as loop transformations,
peephole optimization and automatic vectorizers are performed by
commodity compilers to improve the performance of the generated code.
%
However, optimizing compilers have several limitations, making them
less effective in optimizing code for novel architectures:

\begin{itemize}

    \item Compiler optimizations are not complete: they may not be
able to discover all possible optimizations that can be applied to a
program.
%
Optimizations might be overlooked by a compiler simply due to limited
engineering resources.
%
Some of the optimizations might be too complex to be implemented in a
compiler, for example, a compiler may not be able to perform
inter-procedural optimizations that require analyzing the entire
program, which is computationally expensive.
%
Furthermore, existing compilers and optimization tools may not fully
support or exploit the capabilities of these architectures, leading to
suboptimal performance.
%
As a result, as of May 13, 2024, there are 650 open Github issues
that are tagged with \texttt{missed-optimization} in the LLVM repository,
indicating that there are still many optimizations to be discovered.


\item Compiler optimizations are not always correct, and newly
introduced optimizations are more likely to be incorrect. Programs
compiled with incorrect optimizations may produce incorrect results,
crashes, or security vulnerabilities in runtime.
%
Researchers have been working on the correctness of
compiler optimizations for decades, they have developed various
techniques, including formal verification, fuzzy testing, differential
testing and translation validation to ensure the correctness of
validation.
%
However, these techniques are not perfect, and there are
still bugs in the compiler optimizations that are discovered from time
to time.


\item Compilers are usually designed in a way that each optimization
work in isolation, and the interaction between different optimizations
are not well understood.
%
For example, an early optimization may change the code in a way that
the later optimization cannot recognize, causing a suboptimal code
generation.
%
Tracing and debugging the interaction between optimizations is hard in
major commodity compilers, making it even more difficult to understand
and diagnose the performance issues.

\item Compilers are not always easy to use. To generate the most
optimized code, developers need to understand the compiler
optimization flags and options, and how to use them effectively.
%
These are usually not well documented, and developers need to spend
time to experiment with different flags and options to find the best
combination.
%
A wrong optimization flag or option may lead to significant
performance degradation.

\end{itemize}

The limitations of human experts and optimizing compilers in
optimizing code for novel architectures motivated this research
to explore program synthesis as an alternative approach to
performance optimization.

\section{Program Synthesis for Performance Optimization}

Program synthesis is a promising approach to address the challenge of
optimizing software for novel architectures.
%
At its core, program synthesis searches for programs that meet a
specified set of requirements.
%
Nowadays, the advances in SMT solvers and increased computation power
have made program synthesis a more viable choice for performance optimization.
%
There are several reasons why program synthesis can help address the
challenge:

\begin{itemize}
    \item \textbf{Semantic as a first-class citizen}: Instead of using
    compiler heuristics where the semantics of an instruction are treated
    as a black box, program synthesis can take the semantics of an
    instruction as input, and generate code that takes full advantage
    of the instruction. This is particularly useful for novel
    architectures where the semantics of the instructions are not well
    handled by existing compilers.

    \item \textbf{Domain-specific optimizations}: Program synthesis
    can be designed to take into account the characteristics of a
    specific domain, such as collective algorithms in parallel
    computation, to create highly optimized code.
    %
    This domain-aware optimization further enhances the performance of
    applications on new architectures.

    \item \textbf{Correctness and Verifiability}: Program synthesis
    can generate code that is correct by construction, and can be.
    %
    This is particularly important for safety-critical applications,
    where correctness is paramount.

    \item \textbf{Optimality}: Program synthesis usually explores the
    entire search space of possible optimizations, and finds the
    optimal solution that meets the requirements. This is in contrast
    to optimizing compilers that use heuristics to determine the best
    optimization strategies. With program synthesis, we can be sure
    that the generated code is optimal with respect to the
    requirements.

    \item \textbf{Continuous improvement}: As an architecture evolves
    and new features are introduced, program synthesis techniques can
    be updated to incorporate these advancements, ensuring that the
    generated code remains optimized over time.
\end{itemize}

This dissertation focuses on developing program synthesizers that aim
to efficiently optimize software for emerging architectures.


\section{Minotaur: A Synthesizing Superoptimizer}

To address above challenges, this dissertation proposes a synthesizing
superoptimizer, called Minotaur, that can automatically generate
peephole optimizations for floating point and vector instructions that
are missing from a commodity compiler.

Minotaur is a synthesis-based superoptimizer for the LLVM intermediate
representation (LLVM IR) that focuses on LLVM's floating point operations,
portable vector operations as well as its Intel-specific intrinsics.
The objective of Minotaur is to automatically identify valuable
optimizations that LLVM is currently unable to perform.
Minotaur is designed to be used as a drop-in replacement for Clang/LLVM.
Minotaur is hundreds of times slower than \texttt{clang -O3} when its
cache is cold, but with a warm cache, it is just 3\% slower, when
building the SPEC CPU 2017 benchmarks.

Minotaur works on code fragments that do not span multiple loop
iterations; it is based on the assumption that existing compiler
optimization passes such as loop unrolling, software pipelining, and
automatic vectorization will create the necessary opportunities for
its optimizations to work effectively.

Minotaur uses an enumerative search algorithm to explore the space of
possible optimizations and a refinement checker to verify the
correctness of the optimizations.
Minotaur uses a cost model to evaluate the performance of the
optimizations, and a cache to store the discovered optimizations.

Minotaur finds many profitable optimizations that are missing from
LLVM,
%
I have sent reports of the missing optimizations to the LLVM community;
some of them have been implemented.
%


Minotaur achieves speedups on various benchmarks and
real-world applications, including the integer parts of SPEC CPU2017,
GMP, and libYUV. Minotaur gets an average 4\%, 0.5\% and 1.1\% speedups
on GMP, libYUV and SPEC CPU17, respectively. The maximum speedup on
real-world applications is 15\% in GMP. TODO: update

\section{Synthesizing Optimal Collective Algorithms}

In addition to Minotaur, this dissertation also proposes a synthesizer
for collective communication algorithms, called SCCL, that can
automatically generate high-performance communication kernels for
specific network topologies.

The convergence of recent trends of training and deploying large
models, and the stagnation of single processors' performance, has
prompted system designers to incorporate innovative high-bandwidth
interconnect networks within and between nodes in distributed
clusters.
%
For example, the NVIDIA DGX-1 server features two x86 processors and
eight GPUs, connected by NVIDIA's NVLink network.
%
These network designs are driven not only by the need for efficient
data transfer, but also by hardware factors such as signal integrity,
cooling, and physical layout.
%
These novel topologies require novel communication kernels to maximize
performance.
%
Currently, these kernels are created and optimized manually.

SCCL is a program synthesizer that, given a topology, specified as a
graph with bandwidth constraints on nodes and edges, and a
communication primitive, specified as the pre- and post-condition on
data locations, it generates a quantifier-free SMT formula that
captures the set of all feasible algorithms that implement the
primitive on the input topology.

SCCL efficiently lowers algorithms to implementations on two systems
(NVIDIA DGX-1 and Gigabyte AMD Z52) and demonstrates competitive
performance with hand-optimized collective communication libraries.
SCCL synthesizes novel latency and bandwidth optimal algorithms not
seen in the literature on two popular hardware topologies. SCCL can be
used as a drop-in replacement for NCCL. SCCL archives a 1.64x speedup
on All Reduce, a 1.5x speedup on All Gather over NCCL.



\section{Contributions}

Overall, my work consists of two main parts: Minotaur, a synthesizing
superoptimizer for LLVM IR, and SCCL, a synthesizer for collective
communication algorithms. The main contributions of this dissertation
are as follows:

\emph{Minotaur: A synthesis-based superoptimizer} I developed
Minotaur, a synthesizing superoptimizer for the LLVM intermediate
representation (LLVM IR) that focuses on LLVM's floating point
operations, portable vector operations as well as its Intel-specific
intrinsics. Specifically, I made the following contributions:

\begin{itemize}
    \item I designed and implemented a domain-specific program
    transformer that extracts an SSA value from an LLVM function,
    along with context about how that value was computed.
    Extracting enough context to permit interesting optimizations,
    without extracting so much context that the underlying SMT
    solver was overwhelmed, was an interesting empirical problem.

    \item I created a synthesis engine that searches for cheaper code
    sequences; it enumerates partially symbolic candidates where the
    instructions are concrete, but data values are symbolic.
    \item I developed infrastructure for caching optimizations and also
    for applying them to code that is being compiled.
    %
    All together, these elements run inside of an LLVM optimization pass.
    \item I performed a detailed evaluation of Minotaur's ability to
    speed up code, showing that it can find numerous optimziations that
    LLVM fails to perform, and also that it can achieve speedups on a
    variety of real-world libraries and benchmarks.
\end{itemize}

\emph{SCCL: A Collective Algorithm Synthesizer} In addition to
Minotaur, I and my collaborators also developed SCCL, a synthesizer
for collective communication algorithms. We've made the following
contributions:

\begin{itemize}
\item A formalization of the synthesis problem for broadcasting
collectives.

\item A general strategy for encoding the synthesis problem for
collective communications algorithms into the quantifier-free linear
integer arithmetic (QF\_LIA) sub-logic of the SMT-LIB logic.

\item A reduction from the synthesis problem for reducing collectives
to that for broadcasting collectives.

\item A description of how SCCL generates efficient code for the
algorithms we synthesize on nodes with NVIDIA or AMD GPUs.

\item An evaluation of SCCL's generated algorithms on common server
topologies for deep learning workloads and a comparison against NCCL.

\end{itemize}

\section{Dissertation Outline}

The rest of this dissertation is organized as follows. In Chapter 2, we
provide background information on superoptimization, SIMD architectures,
and program synthesis. In Chapter 3, we present a verification framework
for LLVM vector instructions. In Chapter 4, we introduce Minotaur and
describe its architecture and implementation. Chapter 5 presents SCCL,
a synthesizer for collective communication algorithms. Finally in Chapter
6, we conclude with a summary of our contributions and directions for
future work.